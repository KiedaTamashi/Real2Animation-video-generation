1/now working:
we train the model first by the 16 kps real pose data, and then freeze the front conv layers(maybe half or more),
add a FC layer in the last, finetune the model to learning a mapping of unpaired keypoints.
The advantage is that we fully use the datasets.

And something else maybe useful is the pretrained model, e.g. VGG, mobileNet.
The framework I prepare to use "https://github.com/Daniil-Osokin/gccpm-look-into-person-cvpr19.pytorch" is acutally
finetuned from image pretrained model because the competition datasets only have 30,462 images for trainning.
Maybe we can directly train on our anime datasets?(over 10,000 after data augmentation)

2/MMD works research.
OpenMMD: https://github.com/peterljq/OpenMMD
Chinese Tutorial: https://www.bilibili.com/read/cv3400259

3/openmmd works.
Following the steps.
I use pmxeditor generate the bone csv file.

[the basic anime pose estiamtion is OK, but something strange is for different dataset, they perform good on differnet images.
I consider that it is because of the limited data. e.g. 7png ]
Next:2/12

1/find datasets (MMD model)
2/winAPPdriver automatic
3/visualize the features and find sth similiar.