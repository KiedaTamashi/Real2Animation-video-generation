1/有些server被block了，连不上。最大的问题还是GPU一直busy根本轮不到我用

2/now working:
we train the model first by the 16 kps real pose data, and then freeze the front conv layers(maybe half or more),
add a FC layer in the last, finetune the model to learning a mapping of unpaired keypoints.
The advantage is that we fully use the datasets.

And something else maybe useful is the pretrained model, e.g. VGG, mobileNet.
The framework I prepare to use "https://github.com/Daniil-Osokin/gccpm-look-into-person-cvpr19.pytorch" is acutally
finetuned from image pretrained model because the competition datasets only have 30,462 images for trainning.
Maybe we can directly train on our anime datasets?(over 10,000 after data augmentation)

3/Blender 是可以3D -> 2D的，我也找到了一些useful free 3D model
tutorial: https://www.youtube.com/watch?v=vIKJ1AqfI0Q
models: https://sketchfab.com/search?features=downloadable&q=anime&sort_by=-pertinence&type=models

4/MMD works research.

Next:
1/Modify LipTrainDataset or Write a new dataset loader
2/set a plan for optimizer parameters updating.