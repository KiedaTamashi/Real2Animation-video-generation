1/now working:
we train the model first by the 16 kps real pose data, and then freeze the front conv layers(maybe half or more),
add a FC layer in the last, finetune the model to learning a mapping of unpaired keypoints.
The advantage is that we fully use the datasets.

And something else maybe useful is the pretrained model, e.g. VGG, mobileNet.
The framework I prepare to use "https://github.com/Daniil-Osokin/gccpm-look-into-person-cvpr19.pytorch" is acutally
finetuned from image pretrained model because the competition datasets only have 30,462 images for trainning.
Maybe we can directly train on our anime datasets?(over 10,000 after data augmentation)

2/MMD works research.
OpenMMD: https://github.com/peterljq/OpenMMD
Chinese Tutorial: https://www.bilibili.com/read/cv3400259

3/openmmd works.
Following the steps.
I use pmxeditor generate the bone csv file.

[the basic anime pose estiamtion is OK, but something strange is for different dataset, they perform good on differnet images.
I consider that it is because of the limited data. e.g. 7png ]

2/13 data collection and process of pmx file is basically over.
75 models. next to collect them when free
from -https://bowlroll.net/file/keyword/MMD >20190801
     -http://mmd.xiaolindraw.com/
     -https://www.deviantart.com/mmd-downloads-galore/gallery/39472353/models


Next:3/4
plan:
3/5 C-VAE data all prepared.
3/6-7 check pose estiamtion performation on data. DEBUG  vae
3/8 train.