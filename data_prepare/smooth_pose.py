import pandas as pd
import numpy as np
import cv2, os
import scipy
from scipy import signal
import csv
from pose_estimate.process_imgs import load_json,write_json
import time

def smooth_json_pose(json_dir,window_length=15,polyorder=3,threshold=0.15):
    data, previous_x, previous_y = [],[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
    fileList = os.listdir(json_dir)
    fileList.sort(key=lambda x:int(x.split("_")[-2]))
    for file in fileList:
        x_data, y_data = [], []
        pose = load_json(os.path.join(json_dir,file))['people'][0]['pose_keypoints_2d']
        for idx in range(0,len(pose),3):
            x,y,prob = pose[idx],pose[idx+1],pose[idx+2]
            if prob > threshold:
                x_data.append(x)
                y_data.append(y)
                # xy = tuple(np.array([x, y], int))
                # cv2.circle(img, xy, 5, (25, 0, 255), 5)
                # No? us the location in the previous frame
            else:
                x_data.append(previous_x[int(idx/3)])
                y_data.append(previous_y[int(idx/3)])
        data.append(x_data + y_data)
        previous_x, previous_y = x_data, y_data
        # use this break statement to check your data before processing the whole video
        # if frame_number == 300: break
    df = pd.DataFrame(data)
    # Smooth it out
    smooth_df = smoothPose(df,window_length=window_length,polyorder=polyorder)

    for idx,file in enumerate(fileList):
        pose_list=[]
        content = load_json(os.path.join(json_dir, file))
        values = np.array(smooth_df.values[idx])
        points = list(zip(values[:18], values[18:]))
        for point in points:
            pose_list.append(point[0])
            pose_list.append(point[1])
            pose_list.append(float(0.9))
        content['people'][0]['pose_keypoints_2d'] = pose_list
        write_json(os.path.join(json_dir,file),content)



def smoothPose(pose_df,input_source=None,output_video=None,window_length=15,polyorder=3):
    '''
    :param json_dir: json_file from video2keypoints
    :param input_source: original video
    :param output_video:
    :param window_length:9-31 is recommended. larger the smoother, but lower accuracy of the point.
    After test, ~<frame_rate/2 is good
    :param polyorder: 3/2
    :return:
    '''
    # Smooth it out
    for i in range(36):
        pose_df[i] = signal.savgol_filter(pose_df[i], window_length, polyorder)

    # Demo Show
    if input_source is None and output_video is None:
        print("No Demo for None input")
    else:
        # There are 15 points in the skeleton
        # TODO now only for 18 kps datasets.
        pairs = [[0, 1],  # head
                 [1, 2], [1, 5], [1,8],[1,11], # sholders
                 [2, 3], [3, 4], [5, 6], [6, 7],  # arms
                 [0, 14], [0, 15], [14, 16], [15,17], # hips
                 [8, 9], [9, 10], [11, 12], [12, 13]]  # legs
        circle_color, line_color = (255, 255, 0), (0, 0, 255)
        # # Get pose data - data is generated by OpenPose
        cap = cv2.VideoCapture(input_source)
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)))
        height = (int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))
        out = cv2.VideoWriter(output_video,
                              cv2.VideoWriter_fourcc('X', 'V', 'I', 'D'), fps, (width, height))
        frame_number = 0
        while True:
            print(frame_number)
            ret, img = cap.read()
            if not ret: break
            # img = np.zeros_like(img)
            ######## this is special for the format of input
            values = np.array(pose_df.values[frame_number], int)
            points = list(zip(values[:18], values[18:]))
            #################################################
            # normally should be (num, 2), where 2 is x,y pair
            cc = 0
            for point in points:
                cc += 90
                xy = tuple(np.array([point[0], point[1]], int))
                cv2.circle(img, xy, 5, (cc, cc, cc), 5)

            # Draw Skeleton
            for pair in pairs:
                partA = pair[0]
                partB = pair[1]
                cv2.line(img, points[partA], points[partB], line_color, 3, lineType=cv2.LINE_AA)

            cv2.imshow('Output-Skeleton', img)
            k = cv2.waitKey(100)
            if k == 27: break
            out.write(img)
            frame_number += 1
        cv2.destroyAllWindows()
    return pose_df


if __name__=="__main__":
    s_t = time.time()
    smooth_json_pose(r"D:\work\OpenMMD1.0\examples\json_out")
    print(time.time() - s_t)